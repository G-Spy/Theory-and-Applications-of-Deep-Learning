{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjpaOlZYqgcd"
      },
      "source": [
        "* **Professor: Hyunsoon Youn**\n",
        "* **Lecture: Theory and Applications of Deep Learning**\n",
        "* **Student name: Sreymouy Sao**\n",
        "* **Student ID: 2021321846**\n",
        "* **Major: Industrial Engineering, Yonsei University**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL4mfNxPlHPS"
      },
      "source": [
        "\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqIhgUM3lPdm"
      },
      "source": [
        "**(a) How many parameters are estimated in this network (including constants)?**\n",
        "\n",
        "From the table of instance in question (b), we can know that there are 10 nodes in the input layer. From the table in question (c), we can know that there are 12 nodes (classes) in the output layer. So the total number of parameters in the network including the constants (biases) equal (10x50 +50)+(50x40+40)+(40x30+30)+(30x12+12) = 4192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvbEjQgPlkn7",
        "outputId": "e9cc27f5-db31-477c-8b5a-514c126ab66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4192\n"
          ]
        }
      ],
      "source": [
        "answer = (10*50 +50)+(50*40+40)+(40*30+30)+(30*12+12) \n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GogjyOCglqcf"
      },
      "source": [
        "(b) **Calculate the value at this node after the sigmoid function is applied.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db0agS_SlCIt",
        "outputId": "c5148605-5c2e-410c-87a2-d71e6549bb96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The answer is :  0.6905163466587109\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import math\n",
        "\n",
        "# weigts\n",
        "w1 = 0.040065\n",
        "w2 = 0.246356\n",
        "w3 = 0.234578\n",
        "w4 = 0.172821\n",
        "w5 = 0.449315\n",
        "w6 = 0.875052\n",
        "w7 = 0.321868\n",
        "w8 = 0.141179\n",
        "w9 = 0.128957\n",
        "w10 = 0.264436\n",
        "w = np.array([w1,w2,w3,w4,w5,w6,w7,w8,w9,w10])\n",
        "\n",
        "# bias\n",
        "b = 0.031945\n",
        "\n",
        "# input\n",
        "x1 = 0.266074\n",
        "x2 = -0.16562\n",
        "x3 = 0.32098\n",
        "x4 = 0.483299\n",
        "x5 = 0.17234\n",
        "x6 = 0.273364\n",
        "x7 = 0.371178\n",
        "x8 = 0.929823\n",
        "x9 = 0.251173\n",
        "x10 = 0.159345\n",
        "x = np.array([x1,x2,x3,x4,x5,x6,x7,x8,x9,x10])\n",
        "\n",
        "# sigmoid function \n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "\n",
        "a = sigmoid(np.dot(w,x)+b)\n",
        "print(\"The answer is : \",a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtQWEyEtzt_E"
      },
      "source": [
        "The answer is : 0.6905163466587109"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdmDKefQl22U"
      },
      "source": [
        "(c) **Calculate the output after a softmax function is applied and estimate the class probabilities for this instance.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9fnUY-llxsk",
        "outputId": "52ec7214-7d94-45cf-ec94-2d6782b9b06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output after softmax function :  [0.05866384 0.10697023 0.12490189 0.06068706 0.0514247  0.02683483\n",
            " 0.05956061 0.11412228 0.10104445 0.07818373 0.12460211 0.09300428]\n",
            "The probability of class  A  is  0.05866384015018051\n",
            "The probability of class  B  is  0.10697022513283515\n",
            "The probability of class  C  is  0.12490188710581969\n",
            "The probability of class  D  is  0.06068706183173598\n",
            "The probability of class  E  is  0.05142469610033901\n",
            "The probability of class  F  is  0.026834826118412414\n",
            "The probability of class  G  is  0.059560614551308344\n",
            "The probability of class  H  is  0.11412228237783695\n",
            "The probability of class  I  is  0.10104445069873268\n",
            "The probability of class  W  is  0.07818372658435027\n",
            "The probability of class  X  is  0.12460210819971389\n",
            "The probability of class  Y  is  0.09300428114873514\n"
          ]
        }
      ],
      "source": [
        "output_before_softmax = np.array([1.197033, 1.79776, 1.952738, 1.23094, 1.065328, \n",
        "                                  0.41491, 1.212204, 1.86248, 1.74077, 1.484271, \n",
        "                                  1.950335, 1.657855])\n",
        "\n",
        "# softmax function\n",
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x))\n",
        "\n",
        "output_after_softmax = softmax(output_before_softmax)\n",
        "class_list = np.array(['A', 'B','C','D','E','F','G','H','I','W','X','Y'])\n",
        "print(\"Output after softmax function : \", output_after_softmax) \n",
        "\n",
        "for i in range(output_after_softmax.size):\n",
        "  print(\"The probability of class \", class_list[i], \" is \", output_after_softmax[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYJIkglRtdkl"
      },
      "source": [
        "(d) **For the instance in part (c), what class is assigned?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Kqg3krnRWs",
        "outputId": "562dce14-3fe6-4e1b-e378-7c9501939845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The assigned class is :  C\n"
          ]
        }
      ],
      "source": [
        "asigned_class = class_list[np.argmax(output_after_softmax)]\n",
        "print(\"The assigned class is : \", asigned_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT7iw7RSz23J"
      },
      "source": [
        "The assigned class is the class that has the maximum probability. It is the class \"C\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SM92reXwTZZ"
      },
      "source": [
        "**Question 3 : For each network below, calculate how many parameters are estimated\n",
        "(including constants).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJhAf1MwoUD"
      },
      "source": [
        "(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIv18_C_wnNL",
        "outputId": "597cf3d0-0489-4bdc-ec42-d8b46f0b2646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of parameters in network (a)  =  822830\n"
          ]
        }
      ],
      "source": [
        "input_nodes = 128*128\n",
        "l1_nodes = 50\n",
        "l2_nodes = 40\n",
        "l3_nodes = 30 \n",
        "output_nodes = 10\n",
        "\n",
        "number_of_parameters = (input_nodes*l1_nodes + l1_nodes) + (l1_nodes*l2_nodes + l2_nodes) + (l2_nodes*l3_nodes + l3_nodes) + (l3_nodes*output_nodes + output_nodes)\n",
        "\n",
        "print(\"The number of parameters in network (a)  = \", number_of_parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQuK1UEw0RLp"
      },
      "source": [
        "The number of parameters in network (a) = 822830"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XkSYQD5yJiV"
      },
      "source": [
        "(b)\n",
        "\n",
        "The size of feature map can be calculated with the formula **feature_map_size = (n+2p-f)/s +1** ;where n is the size of the image, p is the padding, f is the size of the filter and s is the stride. In this network, p=0, s=1 (without stride), f=8, and n=128. Then, feature_map_size = (128-8) +1 = 121. So, the feature map has size 121 x 121. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR1Q068v34rQ"
      },
      "source": [
        "(c)\n",
        "\n",
        "By applying s=4 into the formular in question (b), feature_map_size = [(128-8)/4] +1 = 31. So, the feature map has size 31 x 31.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlTFD3_p4u5q"
      },
      "source": [
        "(d)\n",
        "\n",
        "Without using weigh sharing, each feature in the feature maps learn different weights and biases.\n",
        "\n",
        "* A 8x8 filter between input and first hidden\n",
        "layer (with stride = 4 and a different bias for each hidden node) has number of parameters **p1 = parameter_for_each_feature_map X size_of_feature_map**. \n",
        "\n",
        "  We have :\n",
        "  * parameter_for_each_feature_map = 8x8 + 1 = 65\n",
        "  * size_of_feature_map = [(128-8)/4 +1] = 31\n",
        "\n",
        "  => p1 = 65 x 31 x 31 = 62465\n",
        "\n",
        "* A 8x8 filter between first and second hidden layer (with stride = 4 and a different bias for each hidden node) has number of parameters **p2 = parameter_for_each_feature_map X size_of_feature_map**.\n",
        "\n",
        "  We have :\n",
        "  * parameter_for_each_feature_map = 8x8 + 1 = 65\n",
        "  * size_of_feature_map = [int((31-8)/4) +1] = 6\n",
        "\n",
        "  => p2 = 65 x 6 x 6 = 2340\n",
        "\n",
        "* A fully connected output layer has the parameter p3 = size_of_feature_map x size_of_feature_map x 10 + 10 = 6 x 6 x 10 + 10 = 370\n",
        "\n",
        "**The total number of parameters p = p1 + p2 + p3 = 62450 + 2340 + 370 = 65160**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LF3W7B-DRuS"
      },
      "source": [
        "(e) \n",
        "\n",
        "With weight sharing, the network is the convolutional network. \n",
        "\n",
        "*   A 8x8 filter between input and first hidden layer (with stride = 4 and a shared bias for each feature map) has number of parameters p1 = 8x8 +1 = 65. \n",
        "*   A 8x8 filter between first and second hidden layer (with stride = 4 and a shared bias for each feature map) has number of parameters p2 = 8x8 +1 = 65.\n",
        "*   A fully connected output layer has number of parameters p3 = size_of_feature_map x size_of_feature_map x 10 + 10 = 6 x 6 x 10 + 10 = 370\n",
        "\n",
        "**The total number of parameters p = p1 + p2 + p3 = 65 + 65 + 370 = 500**.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Take_Home_Exam_Q1_and_Q3_sao_sreymouy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
